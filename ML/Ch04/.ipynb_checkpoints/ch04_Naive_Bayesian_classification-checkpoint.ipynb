{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error 2] : u'ch04'\n",
      "C:\\pydev\\machinelearninginaction\\Ch04\n"
     ]
    }
   ],
   "source": [
    "cd ch04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'C:\\\\pydev\\\\machinelearninginaction\\\\Ch04'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.pyc'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
       " ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
       " ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
       " ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
       " ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
       " ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_post, class_label = bayes.loadDataSet()\n",
    "list_of_post\n",
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']\n",
      "document: set(['help', 'please', 'problems', 'dog', 'flea', 'has', 'my'])\n",
      "document: ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']\n",
      "document: ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid']\n",
      "document: set(['maybe', 'park', 'dog', 'to', 'stupid', 'take', 'not', 'him'])\n",
      "document: ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid']\n",
      "document: ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him']\n",
      "document: set(['cute', 'love', 'I', 'is', 'dalmation', 'so', 'my', 'him'])\n",
      "document: ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him']\n",
      "document: ['stop', 'posting', 'stupid', 'worthless', 'garbage']\n",
      "document: set(['worthless', 'stupid', 'stop', 'posting', 'garbage'])\n",
      "document: ['stop', 'posting', 'stupid', 'worthless', 'garbage']\n",
      "document: ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him']\n",
      "document: set(['licks', 'to', 'stop', 'how', 'ate', 'mr', 'steak', 'my', 'him'])\n",
      "document: ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him']\n",
      "document: ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']\n",
      "document: set(['quit', 'worthless', 'food', 'dog', 'stupid', 'buying'])\n",
      "document: ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']\n"
     ]
    }
   ],
   "source": [
    "my_vocab_list = bayes.createVocabList_lec(list_of_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returnVec: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word: my\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: my\n",
      "----->vocablist.index(word): 31\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n",
      "word: dog\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: dog\n",
      "----->vocablist.index(word): 24\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n",
      "word: has\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: has\n",
      "----->vocablist.index(word): 18\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n",
      "word: flea\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: flea\n",
      "----->vocablist.index(word): 10\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n",
      "word: problems\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: problems\n",
      "----->vocablist.index(word): 6\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n",
      "word: help\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: help\n",
      "----->vocablist.index(word): 2\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n",
      "word: please\n",
      "vocabList: ['cute', 'love', 'help', 'garbage', 'quit', 'I', 'problems', 'is', 'park', 'stop', 'flea', 'dalmation', 'licks', 'food', 'not', 'him', 'buying', 'posting', 'has', 'worthless', 'ate', 'to', 'maybe', 'please', 'dog', 'how', 'stupid', 'so', 'take', 'mr', 'steak', 'my']\n",
      "\n",
      "----->word: please\n",
      "----->vocablist.index(word): 23\n",
      "----->returnVec[vocabList.index(word)]: 0\n",
      "----->returnvec[vocabList.index(word)]: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_post[0]\n",
    "bayes.setOfWords2Vec_lec(my_vocab_list, list_of_post[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_post[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.setOfWords2Vec(my_vocab_list, list_of_post[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.pyc'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testingNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_post, class_label = bayes.loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_vocab_list = bayes.createVocabList(list_of_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMat = []\n",
    "for post in list_of_post:\n",
    "    trainMat.append(bayes.setOfWords2Vec(my_vocab_list,  post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMat[0:2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainMat2 = [bayes.setOfWords2Vec(my_vocab_list, post) for ost in list_of_post]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMat == trainMat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainMat[0])\n",
    "print(trainMat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porb. of abusive: 0.5\n",
      "\n",
      "-->i: 0\n",
      "-->if trainCategory[0] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[0]\n",
      "----> p0Num: [ 1.  1.  2.  1.  1.  1.  2.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.\n",
      "  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  2.]\n",
      "----> p0Denom: 9.0\n",
      "\n",
      "-->i: 1\n",
      "-->if trainCategory[1] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[1]\n",
      "----> p1Num: [ 1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  2.  2.  1.  1.\n",
      "  1.  1.  1.  2.  2.  1.  2.  1.  2.  1.  2.  1.  1.  1.]\n",
      "----> p1Denom: 10.0\n",
      "\n",
      "-->i: 2\n",
      "-->if trainCategory[2] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[2]\n",
      "----> p0Num: [ 2.  2.  2.  1.  1.  2.  2.  2.  1.  1.  2.  2.  1.  1.  1.  2.  1.  1.\n",
      "  2.  1.  1.  1.  1.  2.  2.  1.  1.  2.  1.  1.  1.  3.]\n",
      "----> p0Denom: 17.0\n",
      "\n",
      "-->i: 3\n",
      "-->if trainCategory[3] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[3]\n",
      "----> p1Num: [ 1.  1.  1.  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.  1.  2.\n",
      "  1.  2.  1.  2.  2.  1.  2.  1.  3.  1.  2.  1.  1.  1.]\n",
      "----> p1Denom: 15.0\n",
      "\n",
      "-->i: 4\n",
      "-->if trainCategory[4] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[4]\n",
      "----> p0Num: [ 2.  2.  2.  1.  1.  2.  2.  2.  1.  2.  2.  2.  2.  1.  1.  3.  1.  1.\n",
      "  2.  1.  2.  2.  1.  2.  2.  2.  1.  2.  1.  2.  2.  4.]\n",
      "----> p0Denom: 26.0\n",
      "\n",
      "-->i: 5\n",
      "-->if trainCategory[5] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[5]\n",
      "----> p1Num: [ 1.  1.  1.  2.  2.  1.  1.  1.  2.  2.  1.  1.  1.  2.  2.  2.  2.  2.\n",
      "  1.  3.  1.  2.  2.  1.  3.  1.  4.  1.  2.  1.  1.  1.]\n",
      "----> p1Denom: 21.0\n",
      "---------->p1Vect: [-3.04452244 -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244 -3.04452244\n",
      " -3.04452244 -2.35137526 -2.35137526 -2.35137526 -2.35137526 -2.35137526\n",
      " -3.04452244 -1.94591015 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
      " -1.94591015 -3.04452244 -1.65822808 -3.04452244 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244]\n",
      "---------->p0Vect: [-2.56494936 -2.56494936 -2.56494936 -3.25809654 -3.25809654 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -2.56494936 -2.56494936\n",
      " -2.56494936 -3.25809654 -3.25809654 -2.15948425 -3.25809654 -3.25809654\n",
      " -2.56494936 -3.25809654 -2.56494936 -2.56494936 -3.25809654 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -2.56494936\n",
      " -2.56494936 -1.87180218]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -2.56494936, -2.56494936, -2.56494936, -3.25809654, -2.56494936,\n",
       "        -2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -2.15948425, -3.25809654, -3.25809654, -2.56494936, -3.25809654,\n",
       "        -2.56494936, -2.56494936, -3.25809654, -2.56494936, -2.56494936,\n",
       "        -2.56494936, -3.25809654, -2.56494936, -3.25809654, -2.56494936,\n",
       "        -2.56494936, -1.87180218]),\n",
       " array([-3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -2.35137526, -2.35137526, -2.35137526, -3.04452244, -1.94591015,\n",
       "        -3.04452244, -2.35137526, -2.35137526, -3.04452244, -1.94591015,\n",
       "        -3.04452244, -1.65822808, -3.04452244, -2.35137526, -3.04452244,\n",
       "        -3.04452244, -3.04452244]),\n",
       " 0.5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.trainNB0_lec(trainMat, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cute',\n",
       " 'love',\n",
       " 'help',\n",
       " 'garbage',\n",
       " 'quit',\n",
       " 'I',\n",
       " 'problems',\n",
       " 'is',\n",
       " 'park',\n",
       " 'stop',\n",
       " 'flea',\n",
       " 'dalmation',\n",
       " 'licks',\n",
       " 'food',\n",
       " 'not',\n",
       " 'him',\n",
       " 'buying',\n",
       " 'posting',\n",
       " 'has',\n",
       " 'worthless',\n",
       " 'ate',\n",
       " 'to',\n",
       " 'maybe',\n",
       " 'please',\n",
       " 'dog',\n",
       " 'how',\n",
       " 'stupid',\n",
       " 'so',\n",
       " 'take',\n",
       " 'mr',\n",
       " 'steak',\n",
       " 'my']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porb. of abusive: 0.5\n",
      "\n",
      "-->i: 0\n",
      "-->if trainCategory[0] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[0]\n",
      "----> p0Num: [ 1.  1.  2.  1.  1.  1.  2.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.\n",
      "  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.  1.  2.]\n",
      "----> p0Denom: 9.0\n",
      "\n",
      "-->i: 1\n",
      "-->if trainCategory[1] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[1]\n",
      "----> p1Num: [ 1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  2.  2.  1.  1.\n",
      "  1.  1.  1.  2.  2.  1.  2.  1.  2.  1.  2.  1.  1.  1.]\n",
      "----> p1Denom: 10.0\n",
      "\n",
      "-->i: 2\n",
      "-->if trainCategory[2] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[2]\n",
      "----> p0Num: [ 2.  2.  2.  1.  1.  2.  2.  2.  1.  1.  2.  2.  1.  1.  1.  2.  1.  1.\n",
      "  2.  1.  1.  1.  1.  2.  2.  1.  1.  2.  1.  1.  1.  3.]\n",
      "----> p0Denom: 17.0\n",
      "\n",
      "-->i: 3\n",
      "-->if trainCategory[3] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[3]\n",
      "----> p1Num: [ 1.  1.  1.  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.  1.  2.\n",
      "  1.  2.  1.  2.  2.  1.  2.  1.  3.  1.  2.  1.  1.  1.]\n",
      "----> p1Denom: 15.0\n",
      "\n",
      "-->i: 4\n",
      "-->if trainCategory[4] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[4]\n",
      "----> p0Num: [ 2.  2.  2.  1.  1.  2.  2.  2.  1.  2.  2.  2.  2.  1.  1.  3.  1.  1.\n",
      "  2.  1.  2.  2.  1.  2.  2.  2.  1.  2.  1.  2.  2.  4.]\n",
      "----> p0Denom: 26.0\n",
      "\n",
      "-->i: 5\n",
      "-->if trainCategory[5] == 1\n",
      "-->trainCategory: [0, 1, 0, 1, 0, 1]\n",
      "----> trainMatrix[5]\n",
      "----> p1Num: [ 1.  1.  1.  2.  2.  1.  1.  1.  2.  2.  1.  1.  1.  2.  2.  2.  2.  2.\n",
      "  1.  3.  1.  2.  2.  1.  3.  1.  4.  1.  2.  1.  1.  1.]\n",
      "----> p1Denom: 21.0\n",
      "---------->p1Vect: [-3.04452244 -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244 -3.04452244\n",
      " -3.04452244 -2.35137526 -2.35137526 -2.35137526 -2.35137526 -2.35137526\n",
      " -3.04452244 -1.94591015 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
      " -1.94591015 -3.04452244 -1.65822808 -3.04452244 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244]\n",
      "---------->p0Vect: [-2.56494936 -2.56494936 -2.56494936 -3.25809654 -3.25809654 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -2.56494936 -2.56494936\n",
      " -2.56494936 -3.25809654 -3.25809654 -2.15948425 -3.25809654 -3.25809654\n",
      " -2.56494936 -3.25809654 -2.56494936 -2.56494936 -3.25809654 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -2.56494936\n",
      " -2.56494936 -1.87180218]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -2.56494936, -2.56494936, -2.56494936, -3.25809654, -2.56494936,\n",
       "        -2.56494936, -2.56494936, -2.56494936, -3.25809654, -3.25809654,\n",
       "        -2.15948425, -3.25809654, -3.25809654, -2.56494936, -3.25809654,\n",
       "        -2.56494936, -2.56494936, -3.25809654, -2.56494936, -2.56494936,\n",
       "        -2.56494936, -3.25809654, -2.56494936, -3.25809654, -2.56494936,\n",
       "        -2.56494936, -1.87180218]),\n",
       " array([-3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -3.04452244, -3.04452244, -3.04452244, -2.35137526, -2.35137526,\n",
       "        -2.35137526, -2.35137526, -2.35137526, -3.04452244, -1.94591015,\n",
       "        -3.04452244, -2.35137526, -2.35137526, -3.04452244, -1.94591015,\n",
       "        -3.04452244, -1.65822808, -3.04452244, -2.35137526, -3.04452244,\n",
       "        -3.04452244, -3.04452244]),\n",
       " 0.5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.trainNB0_lec(trainMat, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porb. of abusive: 0.5\n"
     ]
    }
   ],
   "source": [
    "p0v, p1v, pAbusive = bayes.trainNB0(trainMat, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEntry = ['loe', 'my', 'dalmeation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word: loe is not in my Vocabulary!\n",
      "the word: dalmeation is not in my Vocabulary!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVec = bayes.setOfWords2Vec(my_vocab_list, testEntry)\n",
    "testVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec2Classify: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "p1Vec: [-3.04452244 -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244 -2.35137526 -2.35137526 -3.04452244 -3.04452244\n",
      " -3.04452244 -2.35137526 -2.35137526 -2.35137526 -2.35137526 -2.35137526\n",
      " -3.04452244 -1.94591015 -3.04452244 -2.35137526 -2.35137526 -3.04452244\n",
      " -1.94591015 -3.04452244 -1.65822808 -3.04452244 -2.35137526 -3.04452244\n",
      " -3.04452244 -3.04452244]\n",
      "p0Vec: [-2.56494936 -2.56494936 -2.56494936 -3.25809654 -3.25809654 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -2.56494936 -2.56494936\n",
      " -2.56494936 -3.25809654 -3.25809654 -2.15948425 -3.25809654 -3.25809654\n",
      " -2.56494936 -3.25809654 -2.56494936 -2.56494936 -3.25809654 -2.56494936\n",
      " -2.56494936 -2.56494936 -3.25809654 -2.56494936 -3.25809654 -2.56494936\n",
      " -2.56494936 -1.87180218]\n",
      "pClass1: 0.5\n",
      "p1: -3.73766961828, p0: -2.56494935746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.classifyNB_lec(testVec, p0v, p1v, pAbusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function bayes.testingNB>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.testingNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porb. of abusive: 0.5\n",
      "['love', 'my', 'dalmation'] classified as:  0\n",
      "['stupid', 'garbage'] classified as:  1\n"
     ]
    }
   ],
   "source": [
    "bayes.testingNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testEntry = ['I', 'dumped', 'garbage','for', 'my', 'cute', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word: dumped is not in my Vocabulary!\n",
      "the word: for is not in my Vocabulary!\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "textVec = bayes.setOfWords2Vec(my_vocab_list, testEntry)\n",
    "print testVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.classifyNB(trainMat, p0v, p1v, pAbusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = ['a', 'bc', 'def']; t2 = [1, 2, 'hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_a = []; t_e = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "t.append(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'bc', 'def']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'bc', 'def'], [1, 2, 'hello']]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.append(t2); t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'bc', 'def']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = []\n",
    "tt.extend(t1); tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'bc', 'def', 1, 2, 'hello']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.extend(t2); tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.pyc'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porb. of abusive: 0.525\n",
      "classification error ['yeah', 'ready', 'may', 'not', 'here', 'because', 'jar', 'jar', 'has', 'plane', 'tickets', 'germany', 'for']\n",
      "the error rate is:  0.1\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randIndex = int(np.random.uniform(0, 50))\n",
    "randIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49, 39, 11, 26, 7, 47, 31, 22, 37, 20]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(np.random.uniform(0, 50)) for _ in range(10)]\n",
    "# 중복값이 나온다. \n",
    "# 원래는 다른 값이었어도 소숫점을 버리니까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
